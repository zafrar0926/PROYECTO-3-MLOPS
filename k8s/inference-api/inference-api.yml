apiVersion: apps/v1
kind: Deployment
metadata:
  name: inference-api
  namespace: mlops-proyecto3
spec:
  replicas: 1
  selector:
    matchLabels:
      app: inference-api
  template:
    metadata:
      labels:
        app: inference-api
    spec:
      initContainers:
      - name: wait-for-model
        image: busybox:1.34
        command:
          - sh
          - -c
        args:
          - |
            echo "⏳ Esperando a DiabetesReadmissionModel en MLflow…";
            until wget -qO- \
              "http://mlflow.mlops-proyecto3.svc.cluster.local:5000/api/2.0/mlflow/registered-models/get?name=DiabetesReadmissionModel" \
              | grep -q '"registered_model"' ;
            do
              echo "   aún no está, reintento en 5s…";
              sleep 5;
            done
            echo "✅ Modelo encontrado, continúa el arranque.";

      containers:
      - name: inference
        image: inference-api:latest
        imagePullPolicy: IfNotPresent
        ports:
        - name: http
          containerPort: 8000
        env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow.mlops-proyecto3.svc.cluster.local:5000"
        - name: MLFLOW_MODEL_NAME
          value: "DiabetesReadmissionModel"
        - name: MLFLOW_MODEL_STAGE
          value: "Production"
        - name: AWS_ACCESS_KEY_ID
          value: "minioadmin"
        - name: AWS_SECRET_ACCESS_KEY
          value: "minioadmin"
        - name: MLFLOW_S3_ENDPOINT_URL
          value: "http://minio.mlops-proyecto3.svc.cluster.local:9000"

        readinessProbe:
          httpGet:
            path: /metrics
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5

        livenessProbe:
          httpGet:
            path: /metrics
            port: 8000
          initialDelaySeconds: 20
          periodSeconds: 10

        resources:
          requests:
            cpu: 250m
            memory: 512Mi
          limits:
            cpu: 1
            memory: 1Gi

---
apiVersion: v1
kind: Service
metadata:
  name: inference-api
  namespace: mlops-proyecto3
spec:
  selector:
    app: inference-api
  ports:
    - name: http
      port: 80
      targetPort: 8000
  type: ClusterIP
